<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Capture Study</title>
</head>

<body>
    <video id="videoInput"></video>
    <canvas id="canvasFrame"></canvas>
    <canvas id="binary"></canvas>

    <p id="info">Carregando...</p>

    <script async src="libs/opencv0.js" onload="main();" type="text/javascript"></script>
    <script >
        const canvasFrame = document.getElementById("canvasFrame"); // gets <canvas>
        const context = canvasFrame.getContext("2d"); // context

        const video = document.getElementById("videoInput"); // gets <video>
        let width, height;
        // const { width, height } = 
        startVideo(video)
        .then(e => {
            console.log(e);
            width = e.width
            height = e.height
        }); // start video and get its properties

        async function main() {

            const p = document.getElementById("info");
            p.innerHTML = `width: ${width} and height: ${height}`;

            const FPS = 24;
            const src = new cv.Mat(height, width, cv.CV_8UC4); // storages image source
            const dst = new cv.Mat(height, width, cv.CV_8UC4); // storages final result
            const aux = new cv.Mat(height, width, cv.CV_8UC4); // helper mat
            const oldAux = new cv.Mat(height, width, cv.CV_8UC4); // helper mat
            const low = new cv.Mat(dst.rows, dst.cols, cv.CV_8UC3, [0, 133, 77, 0]);
            const high = new cv.Mat(dst.rows, dst.cols, cv.CV_8UC3, [255, 173, 127, 255]);
            const black = new cv.Scalar(0, 0, 0, 255); // helper scalar for black color
            const red = new cv.Scalar(255, 0, 0); // helper scalar for red color
            const mask = new cv.Mat(height, width, cv.CV_8UC4, black); // helper mat

            let contours = new cv.MatVector(); // storages contours
            let hierarchy = new cv.Mat(); // storages hierarchy
            let begin, delay; // fps helpers
            const MIN_AREA = height * width * 0.1;
            let i, areaIdx, area, biggerArea, contour // helpers for fiding largest area

            // https://docs.opencv.org/3.4/dd/d1a/group__imgproc__feature.html#ga1d6bb77486c8f92d79c8793ad995d541
            let [maxCorners, qualityLevel, minDistance, blockSize] = [40, 0.2, 15, 7];
            let hasFeatures = false;
            let features = new cv.Mat();
            let features2 = new cv.Mat();
            let stats = new cv.Mat();
            let err = new cv.Mat()

            // https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323
            let winSize = new cv.Size(15, 15);
            let maxLevel = 2;
            let criteria = new cv.TermCriteria(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03);

            let goodNew = [];
            let goodOld = [];
            let resultant = [];
            let test = [];

            // ---
            let hull = new cv.MatVector();
            let hpts = [];
            let df = [];

            let color = [];
            for (let i = 0; i < maxCorners; i++) {
                color.push(new cv.Scalar(parseInt(Math.random() * 255), parseInt(Math.random() * 255),
                    parseInt(Math.random() * 255), 255));
            }

            let draw = false;
            let count = 0;
            setTimeout(() => { draw = true }, 1000);

            function processVideo() {
                begin = Date.now();

                context.drawImage(video, 0, 0, width, height);
                src.data.set(context.getImageData(0, 0, width, height).data);


                if (!hasHand()) {
                    hasFeatures = false;
                    dst.setTo(black);

                } else {
                    // return;
                    detachForeground();

                    if (!hasFeatures) {
                        cv.goodFeaturesToTrack(aux, features, maxCorners, qualityLevel, minDistance)

                        if (features.rows >= 20) {
                            hasFeatures = true;
                            aux.copyTo(oldAux);
                            mask.setTo(black);

                            for (let i = 0; i < features.rows; i++) {
                                resultant.push(new cv.Point(0, 0));
                            }

                            test.length = 0;
                        }
                    }
                    else {
                        cv.calcOpticalFlowPyrLK(oldAux, aux, features, features2, stats, err, winSize, maxLevel, criteria);

                        goodNew.length = 0;
                        goodOld.length = 0;

                        for (let i = 0; i < stats.rows; i++) {
                            if (stats.data[i] === 1) {
                                goodNew.push(new cv.Point(features2.data32F[i * 2], features2.data32F[i * 2 + 1]));
                                goodOld.push(new cv.Point(features.data32F[i * 2], features.data32F[i * 2 + 1]));

                                // console.log(resultant[i])
                                // resultant[i].x += features2.data32F[i * 2] - features.data32F[i * 2];
                                // resultant[i].y += features2.data32F[i * 2 + 1] - features.data32F[i * 2 + 1];
                                // console.log(features2.data32F[i * 2] - features.data32F[i * 2])
                            }
                        }

                        if (test.length === 0) {
                            for (let i = 0; i < stats.rows; i++) {
                                if (stats.data[i] === 1) {
                                    test.push(new cv.Point(features.data32F[i * 2], features.data32F[i * 2 + 1]));

                                }
                            }
                            count++;
                        }

                        // draw the tracks
                        for (let i = 0; i < goodNew.length; i++) {
                            // cv.circle(dst, goodNew[i], 5, color[i], -1);
                            // cv.line(mask, goodNew[i], goodOld[i], color[i], 2);


                            if (draw && i < test.length) {
                                p.innerHTML = `area: ${biggerArea}`;
                                cv.line(mask, goodOld[i], test[i], color[i], 2);
                                cv.add(dst, mask, dst);
                                cv.imshow("canvasFrame", dst);
                            }
                        }

                        if (hpts.length > 0)
                            for (let i = 0; i < hpts.length; i++) {
                                // cv.circle(dst, { x: hull.get(0).data32S[i * 2], y: hull.get(0).data32S[i * 2 + 1] }, color[i], 2)
                                cv.circle(dst, hpts[i], 5, color[i], 2);
                            }
                        cv.drawContours(mask, hull, 0, color[0], 2, 8, hierarchy, 0);

                        if (draw) {
                            draw = false;
                            hasFeatures = false;
                            setTimeout(() => { draw = true }, 2000);
                            setTimeout(() => {
                                processVideo();
                            }, 1000);
                            count = 0;
                        }
                        cv.add(dst, mask, dst);
                    }
                }

                cv.imshow("canvasFrame", dst);

                aux.copyTo(oldAux);
                // features.delete();
                // features = null;
                // features = new cv.Mat(goodNew.length, 1, cv.CV_32FC2);

                for (let i = 0; i < goodNew.length; i++) {
                    features.data32F[i * 2] = goodNew[i].x;
                    features.data32F[i * 2 + 1] = goodNew[i].y;
                }

                delay = 1000 / FPS - (Date.now() - begin);
                setTimeout(processVideo, delay);
            }
            setTimeout(processVideo, 0);


            // // https://medium.com/@muehler.v/simple-hand-gesture-recognition-using-opencv-and-javascript-eb3d6ced28a0
            // function getRoughHull(contour, maxDist) {
            //     // get hull indices and hull points
            //     const hullIndices = contour.convexHullIndices();
            //     const contourPoints = contour.getPoints();
            //     const hullPointsWithIdx = hullIndices.map(idx => ({
            //         pt: contourPoints[idx],
            //         contourIdx: idx
            //     }));
            //     const hullPoints = hullPointsWithIdx.map(ptWithIdx => ptWithIdx.pt);

            //     // group all points in local neighborhood
            //     const ptsBelongToSameCluster = (pt1, pt2) => ptDist(pt1, pt2) < maxDist;
            //     const { labels } = cv.partition(hullPoints, ptsBelongToSameCluster);
            //     const pointsByLabel = new Map();
            //     labels.forEach(l => pointsByLabel.set(l, []));
            //     hullPointsWithIdx.forEach((ptWithIdx, i) => {
            //         const label = labels[i];
            //         pointsByLabel.get(label).push(ptWithIdx);
            //     });

            //     // map points in local neighborhood to most central point
            //     const getMostCentralPoint = (pointGroup) => {
            //         // find center
            //         const center = getCenterPt(pointGroup.map(ptWithIdx => ptWithIdx.pt));
            //         // sort ascending by distance to center
            //         return pointGroup.sort(
            //             (ptWithIdx1, ptWithIdx2) => ptDist(ptWithIdx1.pt, center) - ptDist(ptWithIdx2.pt, center)
            //         )[0];
            //     };
            //     const pointGroups = Array.from(pointsByLabel.values());
            //     // return contour indices of most central points
            //     return pointGroups.map(getMostCentralPoint).map(ptWithIdx => ptWithIdx.contourIdx);
            // }

            function hasHand() {
                cv.cvtColor(src, aux, cv.COLOR_RGB2YCrCb);
                cv.inRange(aux, low, high, aux);
                cv.findContours(aux, contours, hierarchy, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE);

                areaIdx = -1;
                biggerArea = -1;
                biggerArea = 0;
                for (i = 0; i < contours.size(); i++) {
                    contour = contours.get(i);
                    area = cv.contourArea(contour, false);

                    if (area > biggerArea) {
                        areaIdx = i;
                        biggerArea = area;
                    }
                }

                if (areaIdx > -1) {
                    let tmp = new cv.Mat();
                    let hIdxs = new cv.Mat();
                    let defects = new cv.Mat();

                    mask.setTo(black);

                    let cnt = contours.get(areaIdx);
                    hull.delete();
                    hull = new cv.MatVector();
                    // You can try more different parameters
                    cv.convexHull(cnt, tmp, false, true);
                    hull.push_back(tmp);

                    cv.convexHull(cnt, hIdxs, false, false);
                    cv.convexityDefects(cnt, hIdxs, defects);

                    console.log(defects);

                    hpts.length = 0;
                    for (let i = 0; i < tmp.rows; i++) {
                        let pt = new cv.Point(tmp.data32S[i * 2], tmp.data32S[i * 2 + 1]);

                        let flag = false;

                        for (let j = 0; j < hpts.length; j++) {
                            if (dinstaceSquared(hpts[j], pt) < 1000) {
                                hpts[j].x = (hpts[j].x + pt.x) / 2;
                                hpts[j].y = (hpts[j].y + pt.y) / 2;
                                flag = true;
                            }
                        }

                        if (!flag) {
                            hpts.push(new cv.Point(tmp.data32S[i * 2], tmp.data32S[i * 2 + 1]))
                        }
                    }

                    cnt.delete(); tmp.delete(); hIdxs.delete();
                }

                return areaIdx > -1 && biggerArea >= MIN_AREA;
            }

            function dinstaceSquared(p1, p2) {
                return Math.pow(p2.x - p1.x, 2) + Math.pow(p2.y, - p1.y, 2);
            }

            function detachForeground() {
                aux.setTo(black); // clear aux
                dst.setTo(black); // clear dst
                cv.drawContours(aux, contours, areaIdx, red, -1, cv.LINE_8, hierarchy, 1);

                cv.bitwise_and(src, src, dst, aux);

                dst.copyTo(aux);
                cv.cvtColor(dst, aux, cv.COLOR_RGB2GRAY);
            }

        }

        async function startVideo(video) {
            let stream = null; // video stream
            let width, height; // video size

            const constraints = {
                video: {
                    facingMode: "environment",
                    width: 480,
                    height: 360
                },
                audio: false
            }

            try {
                stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                video.play();

                width = stream.getVideoTracks()[0].getSettings().width
                height = stream.getVideoTracks()[0].getSettings().height

                return { width, height }
            }
            catch (err) {
                console.error('Error accesing camera:', err);
                const p = document.getElementById("info");
                p.innerHTML = 'Error accesing camera - ' + err;
            }

        }
    </script>
</body>

</html>