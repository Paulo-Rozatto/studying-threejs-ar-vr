<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Capture Study</title>
</head>

<body>
    <video id="videoInput"></video>
    <canvas id="canvasFrame"></canvas>
    <canvas id="binary"></canvas>

    <p id="info">Oi</p>

    <script async src="libs/opencv0.js" onload="main();" type="text/javascript"></script>
    <script>
        async function main() {
            const canvasFrame = document.getElementById("canvasFrame"); // gets <canvas>
            const context = canvasFrame.getContext("2d"); // context

            const video = document.getElementById("videoInput"); // gets <video>
            const { width, height } = await startVideo(video); // start video and get its properties

            const p = document.getElementById("info");
            p.innerHTML = `width: ${width} and height: ${height}`;

            const FPS = 24;
            const src = new cv.Mat(height, width, cv.CV_8UC4); // storages image source
            const dst = new cv.Mat(height, width, cv.CV_8UC4); // storages final result
            const aux = new cv.Mat(height, width, cv.CV_8UC4); // helper mat
            const oldAux = new cv.Mat(height, width, cv.CV_8UC4); // helper mat
            const low = new cv.Mat(dst.rows, dst.cols, cv.CV_8UC3, [0, 133, 77, 0]);
            const high = new cv.Mat(dst.rows, dst.cols, cv.CV_8UC3, [255, 173, 127, 255]);
            const black = new cv.Scalar(0, 0, 0, 255); // helper scalar for black color
            const red = new cv.Scalar(255, 0, 0); // helper scalar for red color

            let contours = new cv.MatVector(); // storages contours
            let hierarchy = new cv.Mat(); // storages hierarchy
            let begin, delay; // fps helpers
            const MIN_AREA = height * width * 0.1;
            let i, areaIdx, area, biggerArea, contour // helpers for fiding largest area

            let hasFeatures = false;
            let [maxCorners, qualityLevel, minDistance, blockSize] = [30, .1, 7, 7];
            let features = new cv.Mat();
            let features2 = new cv.Mat();
            let stats = new cv.Mat();
            let err = new cv.Mat()

            let winSize = new cv.Size(15, 15);
            let maxLevel = 2;
            let criteria = new cv.TermCriteria(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03);

            let color = [];
            for (let i = 0; i < maxCorners; i++) {
                color.push(new cv.Scalar(parseInt(Math.random() * 255), parseInt(Math.random() * 255),
                    parseInt(Math.random() * 255), 255));
            }

            function processVideo() {
                begin = Date.now();

                context.drawImage(video, 0, 0, width, height);
                src.data.set(context.getImageData(0, 0, width, height).data);

                cv.cvtColor(src, aux, cv.COLOR_RGB2YCrCb);
                cv.inRange(aux, low, high, aux);
                cv.findContours(aux, contours, hierarchy, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE);

                areaIdx = -1;
                biggerArea = -1;
                biggerArea = 0;
                for (i = 0; i < contours.size(); i++) {
                    contour = contours.get(i);
                    area = cv.contourArea(contour, false);

                    if (area > biggerArea) {
                        areaIdx = i;
                        biggerArea = area;
                    }
                }

                if (areaIdx > -1 && biggerArea >= MIN_AREA) {
                    aux.setTo(black); // clear aux
                    dst.setTo(black); // clear dst
                    cv.drawContours(aux, contours, areaIdx, red, -1, cv.LINE_8, hierarchy, 1);

                    cv.bitwise_and(src, src, dst, aux);

                    dst.copyTo(aux);
                    cv.cvtColor(dst, aux, cv.COLOR_RGB2GRAY);


                    if (!hasFeatures) {
                        cv.goodFeaturesToTrack(aux, features, maxCorners, qualityLevel, minDistance)
                        aux.copyTo(oldAux)
                        console.log(features.rows);
                        if (features.rows >= 20)
                            hasFeatures = true;
                    }
                    else {
                        cv.calcOpticalFlowPyrLK(oldAux, aux, features, features2, stats, err, winSize, maxLevel, criteria);

                        let goodNew = [];
                        let goodOld = [];
                        for (let i = 0; i < stats.rows; i++) {
                            if (stats.data[i] === 1) {
                                goodNew.push(new cv.Point(features2.data32F[i * 2], features2.data32F[i * 2 + 1]));
                                goodOld.push(new cv.Point(features.data32F[i * 2], features.data32F[i * 2 + 1]));
                            }
                        }

                        // draw the tracks
                        for (let i = 0; i < goodNew.length; i++) {
                            cv.circle(dst, goodNew[i], 5, color[i], -1);
                        }
                    }
                }
                else {
                    hasFeatures = false;
                    dst.setTo(black);
                }

                cv.imshow("canvasFrame", dst);

                delay = 1000 / FPS - (Date.now() - begin);
                setTimeout(processVideo, delay);
            }
            setTimeout(processVideo, 0);
        }

        async function startVideo(video) {
            let stream = null; // video stream
            let width, height; // video size

            const constraints = {
                video: {
                    facingMode: "environment",
                    width: 480,
                    height: 360
                },
                audio: false
            }

            try {
                stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                video.play();

                width = stream.getVideoTracks()[0].getSettings().width
                height = stream.getVideoTracks()[0].getSettings().height

                return { width, height }
            }
            catch (err) {
                console.error('Error accesing camera:', err);
            }

        }
    </script>
</body>

</html>